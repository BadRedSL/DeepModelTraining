{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимые импорты и установка сида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 600\n",
    "epochs = 2\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирование датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train = tv.datasets.MNIST('./Datasets', download=True, train=True)\n",
    "MNIST_test = tv.datasets.MNIST('./Datasets', download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MNIST_train.data\n",
    "y_train = MNIST_train.targets\n",
    "X_test = MNIST_test.data\n",
    "y_test = MNIST_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет уникальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 5923\n",
      "1: 6742\n",
      "2: 5958\n",
      "3: 6131\n",
      "4: 5842\n",
      "5: 5421\n",
      "6: 5918\n",
      "7: 6265\n",
      "8: 5851\n",
      "9: 5949\n"
     ]
    }
   ],
   "source": [
    "for i in y_train.unique():\n",
    "    print(f\"{i}: {(y_train==i).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка элементов тренировочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_num = 25\n",
    "plt.imshow(X_train[sample_num], cmap=\"Greys\")\n",
    "plt.title(y_train[sample_num])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходная форма тензора тренировочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.unsqueeze(1).float()\n",
    "X_test = X_test.unsqueeze(1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новая форма тензора тренировочной выборки (добавили 1 канал)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета числа параметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета размера паддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_calc(input_matrix_shape, out_matrix_shape, kernel_size, stride):\n",
    "\n",
    "    padding_h = (stride * (out_matrix_shape[0] - 1) - input_matrix_shape[0] +\n",
    "                 kernel_size[0]) / 2\n",
    "    padding_w = (stride * (out_matrix_shape[1] - 1) - input_matrix_shape[1] +\n",
    "                 kernel_size[1]) / 2\n",
    "    padding_size = [padding_h, padding_w]\n",
    "\n",
    "    return padding_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 2.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_calc([28, 28], [28, 28], [5, 5], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первый подход к созданию сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicLeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                     out_channels=6,\n",
    "                                     kernel_size=5,\n",
    "                                     padding=2)\n",
    "        self.act1 = torch.nn.Tanh()\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6,\n",
    "                                     out_channels=16,\n",
    "                                     kernel_size=5,\n",
    "                                     padding=0)\n",
    "        self.act2 = torch.nn.Tanh()\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
    "        self.act3 = torch.nn.Tanh()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.act4 = torch.nn.Tanh()\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = ClassicLeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61706"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(lenet.parameters(), lr=1.0e-3, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9381)\n",
      "tensor(0.9638)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index + batch_size]\n",
    "        X_batch = X_train[batch_indexes].to(device)\n",
    "        y_batch = y_train[batch_indexes].to(device)\n",
    "\n",
    "        preds = lenet.forward(X_batch)\n",
    "        loss = loss_fn(preds, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_preds = lenet.forward(X_train)\n",
    "    accuracy = (train_preds.argmax(dim=1) == y_train).float().mean().data.cpu()\n",
    "    \n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_preds = lenet.forward(X_test.to(device))\n",
    "print(accuracy_score(y_test.numpy(), test_preds.cpu().detach().numpy().argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другой подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и преобразование датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_mnist = tv.datasets.MNIST('./Datasets/', download=True, transform=trans, train=True)\n",
    "test_ds_mnist = tv.datasets.MNIST('./Datasets/', download=True, transform=trans, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./Datasets/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание дата-лодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_ds_mnist,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=1,\n",
    "                                         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 1, 28, 28])\n",
      "torch.Size([600])\n"
     ]
    }
   ],
   "source": [
    "for i, j in dataloader:\n",
    "    print(i.shape)\n",
    "    print(j.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicLeNet2(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                out_channels=6,\n",
    "                                kernel_size=5,\n",
    "                                padding=2)\n",
    "        act1 = torch.nn.Tanh()\n",
    "        pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        conv2 = torch.nn.Conv2d(in_channels=6,\n",
    "                                out_channels=16,\n",
    "                                kernel_size=5,\n",
    "                                padding=0)\n",
    "        act2 = torch.nn.Tanh()\n",
    "        pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
    "        act3 = torch.nn.Tanh()\n",
    "\n",
    "        fc2 = torch.nn.Linear(120, 84)\n",
    "        act4 = torch.nn.Tanh()\n",
    "\n",
    "        fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "        self.model_part1 = torch.nn.Sequential(conv1, act1, pool1, conv2, act2,\n",
    "                                               pool2)\n",
    "        self.model_part2 = torch.nn.Sequential(fc1, act3, fc2, act4, fc3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.model_part1(x)\n",
    "        out2 = out1.view(out1.size(0),\n",
    "                         out1.size(1) * out1.size(2) * out1.size(3))\n",
    "        out3 = self.model_part2(out2)\n",
    "\n",
    "        return out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = ClassicLeNet2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(lenet.parameters(), lr=1.0e-3, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "  answer = pred.detach().numpy().argmax(1) == label.numpy().argmax(1)\n",
    "  return answer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.895: 100%|██████████| 100/100 [00:06<00:00, 15.39it/s]\n",
      "accuracy: 0.948: 100%|██████████| 100/100 [00:06<00:00, 15.19it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for img, label in (pbar := tqdm(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        label = F.one_hot(label, 10).float()\n",
    "        preds = lenet.forward(img)\n",
    "        \n",
    "        loss = loss_fn(preds, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_current = accuracy(preds.cpu(), label.cpu())\n",
    "        pbar.set_description(f'accuracy: {acc_current:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8465\n"
     ]
    }
   ],
   "source": [
    "X_test = test_ds_mnist.data.unsqueeze(1).float()\n",
    "y_test = test_ds_mnist.targets\n",
    "\n",
    "test_preds = lenet.forward(X_test.to(device))\n",
    "print(accuracy(test_preds.cpu(), F.one_hot(y_test, 10).float().cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba4c651cdc5ec17c511bce19f294202fdc45305f9de1f927c569f32faa173ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
