{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "SEED = 7\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "EPOCHS = 20\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-3\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHANALS = 1\n",
    "OUT_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "  def __init__(self,\n",
    "               batch_size = 1,\n",
    "               num_workers = 2,\n",
    "               train_transforms=None,\n",
    "               val_transforms=None,\n",
    "               ):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.num_workers = num_workers\n",
    "    self.train_transforms = train_transforms\n",
    "    self.val_transforms = val_transforms\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_set = tv.datasets.MNIST('./Datasets/', download=True, transform=self.train_transforms, train=True)\n",
    "    val_test = tv.datasets.MNIST('./Datasets/', download=True, transform=self.val_transforms, train=False)\n",
    "    self.val_set, self.test_set = torch.utils.data.random_split(val_test, [int(0.5*len(val_test)), int(0.5*len(val_test))])\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, in_channels=1, out_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        self.in_channels = in_channels\n",
    "        self.out_classes = out_classes\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model_part_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=self.in_channels,\n",
    "                            out_channels=6,\n",
    "                            kernel_size=5,\n",
    "                            padding=2), torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=6,\n",
    "                            out_channels=16,\n",
    "                            kernel_size=5,\n",
    "                            padding=0), torch.nn.Tanh(),\n",
    "            torch.nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        self.model_part_2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5 * 5 * 16, 120),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(120, 84),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(84, self.out_classes),\n",
    "        )\n",
    "\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.metrics = {\n",
    "            \"accuracy\":\n",
    "            Accuracy(task=\"multiclass\",\n",
    "                     num_classes=self.out_classes).to(device)\n",
    "        }\n",
    "        self.preds_stage = {\n",
    "            \"train\": {\n",
    "                \"loss\": [],\n",
    "                \"accuracy\": []\n",
    "            },\n",
    "            \"valid\": {\n",
    "                \"loss\": [],\n",
    "                \"accuracy\": []\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"loss\": [],\n",
    "                \"accuracy\": []\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model_part_1(x)\n",
    "        out = out.view(out.size(0), out.size(1) * out.size(2) * out.size(3))\n",
    "        out = self.model_part_2(out)\n",
    "        return out\n",
    "\n",
    "    def shared_step(self, sample, stage):\n",
    "        x, y = sample\n",
    "        preds = self.forward(x)\n",
    "        loss = self.loss(preds, y)\n",
    "        self.preds_stage[stage]['loss'].append(loss.detach().cpu())\n",
    "        self.preds_stage[stage]['accuracy'].append(self.metrics[\"accuracy\"](\n",
    "            preds.argmax(dim=1), y).detach().cpu())\n",
    "        return loss\n",
    "\n",
    "    def shared_epoch_end(self, stage):\n",
    "        loss = self.preds_stage[stage]['loss']\n",
    "        loss = torch.stack(loss)\n",
    "        loss = np.mean([x.item() for x in loss])\n",
    "\n",
    "        acc = self.preds_stage[stage]['accuracy']\n",
    "        acc = torch.stack(acc)\n",
    "        acc = np.mean([x.item() for x in acc])\n",
    "\n",
    "        metrics = {f\"{stage}_loss\": loss, f\"{stage}_acc\": acc}\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "        self.preds_stage[stage]['loss'].clear()\n",
    "        self.preds_stage[stage]['accuracy'].clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\":\n",
    "            torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5),\n",
    "            \"interval\":\n",
    "            \"epoch\",\n",
    "            \"monitor\":\n",
    "            \"valid_loss\"\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"train\")\n",
    "\n",
    "    def on_training_epoch_end(self):\n",
    "        return self.shared_epoch_end(\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"valid\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        return self.shared_epoch_end(\"valid\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"test\")\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        return self.shared_epoch_end(\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = tv.transforms.Compose([\n",
    "    tv.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    tv.transforms.ToTensor()    \n",
    "])\n",
    "\n",
    "val_transforms = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor()    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule(BATCH_SIZE, NUM_WORKERS, train_transforms, val_transforms)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = LeNetClassifier(LR, IN_CHANALS, OUT_CLASSES)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(dirpath='models',\n",
    "                    filename='{epoch}_{valid_acc:.2f}_{valid_loss:.2f}',\n",
    "                    save_top_k=2,\n",
    "                    monitor='valid_loss',\n",
    "                    mode='min'),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    EarlyStopping(monitor=\"valid_loss\",\n",
    "                  min_delta=2e-4,\n",
    "                  patience=5,\n",
    "                  verbose=False,\n",
    "                  mode=\"min\")\n",
    "]\n",
    "\n",
    "TENSOR = \"./logs\"\n",
    "logger = TensorBoardLogger(TENSOR, name=\"LeNET\")\n",
    "\n",
    "trainer = pl.Trainer(accelerator= \"gpu\", max_epochs=15, logger=logger, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:604: UserWarning: Checkpoint directory D:\\random\\JupiterProjects\\DeepModelTraining\\DeepImageClassification\\LeNET\\models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | model_part_1 | Sequential       | 2.6 K \n",
      "1 | model_part_2 | Sequential       | 59.1 K\n",
      "2 | loss         | CrossEntropyLoss | 0     \n",
      "--------------------------------------------------\n",
      "61.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.7 K    Total params\n",
      "0.247     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddd698f159a4f7daf18cd9f49256b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037c550c6b16491794e2717b02e0b1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d529c3696b49f0b6eb859b318b7d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4865ac887964169a8a73b62e195753d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37840afd8b76413b8bfd0ad853d006e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09035406dc224519a95cc153635dab65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2e897cc4954b75bd63b6c1b2f7afca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696510c82710468a9f7f86ca44be7a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d82a4003694686b17a2d5c73029cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f870a10271140f7b09b65e0ed3c5227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5764baa59f1d415989c38ca06dd133ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ca123dc77d40f7b7ff51839119292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb204dc2b6ed4c9693b1a48797331f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8d9eacefa14d6ea3d090e0ba7606c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eede18e4f88e4e1190818653ae5cf8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4409fa81e1044c969ff706311b080704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d6c6338d8a4de2a927bca44153b89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = None\n",
    "trainer.fit(model, dm, ckpt_path=CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0607bb89324f1fb56b9c0c1e567937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9814371166828864     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05567945263656637    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9814371166828864    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05567945263656637   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.05567945263656637, 'test_acc': 0.9814371166828864}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13412), started 0:35:44 ago. (Use '!kill 13412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f2a74de452e6b438\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f2a74de452e6b438\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs/LeNET"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba4c651cdc5ec17c511bce19f294202fdc45305f9de1f927c569f32faa173ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
